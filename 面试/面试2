大数据面试    张浩

**策略**

1.  抛砖引玉

2.  反客为主

（自己主动说，不要等着被面试官问，说完一段内容，可以停顿一下，然后接着说）

用A4纸写把项目的部分写下来

**项目介绍部分：**

1.  架构设计（画图）

2.  组件选择（调研+压测）

3.  集群规模

4.  高可靠的实现

5.  压缩格式

6.  文件格式

7.  每秒、每分钟数据量   离线、实时的数据量

8.  哪块高可靠没有做（ flume memory | spark yarn 调优）

9.  集群调优（硬件、Linux、JVM、CDH、HDFS）

开发内容：

1.  Spark、Hive

2.  存储

3.  监控（运维）

补充：

1.  Hive、Spark调优

2.  Bug怎么去解决

3.  算法

4.  机器学习

5.  仓库

6.  YARN怎么调优

7.  CDH资源池

**Java部分**

1.  GC、JVM垃圾选择器参数

2.  Java值传递与对象传递的区别

3.  Java的多继承、多态

4.  Java的sleep和wait的区别

5.  HashMap和HashTable的区别

6.  Java的多线程有哪几种形式

7.  Java接口和抽象类的区别

**大数据部分：**

1.  HDFS读写流程

2.  YARN怎么调整Memory和CPU的资源

3.  MR作业和Spark作业在YARN的流程 

1.  Hive的分组排序

2.  Hive的自定义函数

3.  Hive的left join、left outer join和left semi join的主要区别

1.  有没有阅读过Spark的源码（一定回答阅读过，可以在github上看一下RDD的源码 ） [https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala](https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala)

2.  Spark RDD的五大特性

3.  Spark读取Kafka的两种方式，两者区别

4.  Spark调优

5.  数据倾斜

6.  压缩格式

7.  文件格式

     **大数据项目部分**

1.  集群的规模

2.  每秒、每分钟、每小时、每天的吞吐量

3.  一个作业多大？多少资源？多久跑完

4.  如何设置作业的资源

5.  高可靠

6.  生产的优化

     **其他**

1.  IQ测试题，如果安排在会议室，没有摄像头，可百度搜索这些题

2.  进去公司的时候工资一定要要到位

3.  你还有什么问题吗？ 如果是技术问你，可以问团队构成、方向、技术、分析的东西；如果是HR问你，可以问晋升机制、新人培养问题

4.  你怎么看待加班？可以回答：“如果是工作需要，我会义无反顾的加班，同时我也会提高自己的工作效率，避免不必要的加班”
